# -*- coding: utf-8 -*-
"""
tamaÃ±o_medio_hogares_ccaa.py

Adapted for local execution (Visual Studio Code, plain Python) without Google Colab dependencies.
-------------------------------------------------------------------------
- Eliminates all `google.colab`â€specific imports and `files.download()` calls.
- Replaces hardâ€‘coded Colab paths ("/content/â€¦") with **scriptâ€‘relative** paths.
- All generated CSVs (including `df_original.csv`) now live in a single
  subfolder `data_final/` next to this script, regardless of where you run it.
- Adds networkâ€‘error handling and wraps everything in a `main()` so the module
  can be imported without side effects.

Run from anywhere:
    $ python tamaÃ±o_medio_hogares_ccaa.py

"""

from __future__ import annotations
import io
import sys
import warnings
from pathlib import Path

import pandas as pd
import requests

###############################################################################
# 1. Load original PolicySpace2 data (Brazil) â€“ kept for reference            #
###############################################################################

def load_original_brazil_dataset(url: str) -> pd.DataFrame:
    """Download and load the PolicySpace2 average household size CSV."""
    print("\nğŸ“¥ Downloading Brazilian baseline data â€¦", end=" ")
    response = requests.get(url, timeout=60)
    if response.status_code != 200:
        raise RuntimeError(f"Failed with HTTP {response.status_code} â†’ {url}")
    print("done.")
    return pd.read_csv(io.StringIO(response.content.decode("utf-8")), sep=";")

###############################################################################
# 2. Download INE table on Spanish household size (monthly)                   #
###############################################################################

def download_ine_table(table_code: str) -> pd.DataFrame:
    """Return raw INE table as DataFrame (tabâ€‘separated)."""
    url = (
        f"https://servicios.ine.es/wstempus/csv/ES/DATOS_TABLA/{table_code}?nult=999"
    )
    print(f"ğŸ“¥ Downloading INE table {table_code} â€¦", end=" ")
    response = requests.get(url, timeout=60)
    if response.status_code != 200:
        raise RuntimeError(
            f"Failed to download INE table {table_code} â€“ HTTP {response.status_code}")
    print("done.")
    return pd.read_csv(io.StringIO(response.content.decode("utf-8")), sep="\t")

###############################################################################
# 3. Download mapping Comunidad AutÃ³noma â†” code                               #
###############################################################################

def download_ccaa_mapping() -> pd.DataFrame:
    url = "https://www.ine.es/daco/daco42/codmun/cod_ccaa_provincia.htm"
    print("ğŸ“¥ Downloading CCAA mapping â€¦", end=" ")
    tables = pd.read_html(url, encoding="ISO-8859-1")
    print("done.")
    df_temp = tables[0]
    df_temp.columns = ["CODAUTO", "Comunidad AutÃ³noma", "CPRO", "Provincia"]
    df_temp = df_temp[df_temp["Comunidad AutÃ³noma"] != "Ciudades AutÃ³nomas"]
    df_temp["CODAUTO"] = pd.to_numeric(df_temp["CODAUTO"], errors="coerce")
    df_temp = df_temp.dropna(subset=["CODAUTO"])
    mapping = (
        df_temp[["CODAUTO", "Comunidad AutÃ³noma"]]
        .drop_duplicates("CODAUTO")
        .rename(columns={"CODAUTO": "comunidad_code"})
    )
    return mapping

###############################################################################
# 4. Transform INE monthly series into cleaned annual averages                #
###############################################################################

MES_MAP = {
    "enero": "01",
    "febrero": "02",
    "marzo": "03",
    "abril": "04",
    "mayo": "05",
    "junio": "06",
    "julio": "07",
    "agosto": "08",
    "septiembre": "09",
    "octubre": "10",
    "noviembre": "11",
    "diciembre": "12",
}


def clean_ine_df(df_raw: pd.DataFrame, mapping: pd.DataFrame) -> pd.DataFrame:
    warnings.filterwarnings("ignore")

    df = df_raw.copy()
    df = df.rename(columns={"Comunidades y ciudades autÃ³nomas": "comunidad_name"})

    # Extract year and month
    df["mes"] = df["Periodo"].str.extract(r"de (\w+) de")[0].str.lower().map(MES_MAP)
    df["aÃ±o"] = df["Periodo"].str.extract(r"de (\d{4})")[0].astype(int)

    # Convert Total â†’ float (comma decimal)
    df["total"] = df["Total"].str.replace(",", ".").astype(float)

    # Merge with CCAA codes
    df = df.merge(mapping, left_on="comunidad_name", right_on="Comunidad AutÃ³noma", how="left")

    # Drop unused cols
    df = df.drop(columns=["Periodo", "Total", "Comunidad AutÃ³noma"], errors="ignore")

    # Remove national aggregate
    df = df[df["comunidad_name"] != "Total Nacional"]

    # Fix Castillaâ€‘La Mancha missing code (CODAUTO 8)
    mask = (df["comunidad_name"] == "Castilla-La Mancha") & df["comunidad_code"].isna()
    df.loc[mask, "comunidad_code"] = 8

    # Annual mean by CCAA
    return df.groupby(["comunidad_code", "aÃ±o"], as_index=False)["total"].mean()

###############################################################################
# 5. Persistence helpers                                                     #
###############################################################################

def ensure_output_dir(path: str = "data_final") -> Path:
    """Create (if needed) & return a folder **next to this script**."""
    script_dir = Path(__file__).resolve().parent
    out_dir = (script_dir / path).expanduser()
    out_dir.mkdir(parents=True, exist_ok=True)
    return out_dir


def save_outputs(df_media_anual: pd.DataFrame, out_dir: Path) -> None:
    """Write consolidated & perâ€‘year CSVs inside *out_dir*."""
    consolidated = out_dir / "tamaÃ±o_medio_hogares_ccaa_completo.csv"
    df_media_anual.to_csv(consolidated, index=False)

    for year, df_year in df_media_anual.groupby("aÃ±o"):
        (out_dir / f"tamaÃ±o_medio_hogares_ccaa_{year}.csv").write_text(
            df_year.drop(columns=["aÃ±o"]).to_csv(index=False))

    print("\nğŸ“ Generated files:")
    for path in sorted(out_dir.glob("*.csv")):
        print("   ", path.name)

###############################################################################
# 6. Main execution                                                          #
###############################################################################

def main() -> None:
    print("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("  TamaÃ±o medio de los hogares por CCAA  â€“  ETL pipeline (local)")
    print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    # Ensure output directory first so it can be reused everywhere
    out_dir = ensure_output_dir()

    # Brazilian baseline (optional)
    brazil_url = (
        "https://raw.githubusercontent.com/BAFurtado/PolicySpace2/refs/heads/master/input/"
        "average_num_members_families_2010.csv"
    )
    df_original = load_original_brazil_dataset(brazil_url)
    df_original.to_csv(out_dir / "df_original.csv", encoding="utf-8-sig", index=False)

    # Spain â€“ INE household size
    df_raw = download_ine_table("60132")
    mapping = download_ccaa_mapping()
    df_media_anual = clean_ine_df(df_raw, mapping)

    save_outputs(df_media_anual, out_dir)

    print("\nâœ… Pipeline finished successfully.")

if __name__ == "__main__":
    try:
        main()
    except Exception as exc:
        print("âŒ Error:", exc, file=sys.stderr)
        sys.exit(1)
